{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "616441fc-62fd-43c9-961d-5b4606d02a3a",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell1"
      },
      "source": [
        "## 2026 EY AI & Data Challenge - TerraClimate Data Extraction Notebook\n",
        "\n",
        "This notebooks demonstrates how to access the TerraClimate dataset. TerraClimate is a dataset of monthly climate and climatic water balance for global terrestrial surfaces from 1958 to the present. These data provide important inputs for ecological and hydrological studies at global scales that require high spatial resolution and time-varying data. All data have monthly temporal resolution and a ~4-km (1/24th degree) spatial resolution. This dataset is provided in Zarr format. \n",
        "\n",
        "For more information, visit: [terraclimate- overview](https://planetarycomputer.microsoft.com/dataset/terraclimate#overview) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8dd7a3f-872e-4e04-8267-5d2c1ef4bcf4",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": [
        "## Load In Dependencies\n",
        "The following code installs the required Python libraries (found in the requirements.txt file) in the Snowflake environment to allow successful execution of the remaining notebook code. After running this code for the first time, it is required to “restart” the kernal so the Python libraries are available in the environment. This is done by selecting the “Connected” menu above the notebook (next to “Run all”) and selecting the “restart kernal” link. Subsequent runs of the notebook do not require this “restart” process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba9c9092-a1e5-410b-95cd-568e8bcca686",
      "metadata": {
        "language": "python",
        "name": "cell3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: uv in /Users/shreyasriram/personal_projects/ey/.venv/lib/python3.14/site-packages (0.10.4)\n",
            "\u001b[2mUsing Python 3.14.3 environment at: /Users/shreyasriram/personal_projects/ey/.venv\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m21 packages\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUsing Python 3.14.3 environment at: /Users/shreyasriram/personal_projects/ey/.venv\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m21 packages\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install uv\n",
        "!uv pip install  -r requirements.txt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f9d94d-ecc7-45bf-812d-05d62f3b42d3",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'snowflake.snowpark'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msnowpark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_active_session\n\u001b[32m      3\u001b[39m session = get_active_session()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'snowflake.snowpark'"
          ]
        }
      ],
      "source": [
        "import snowflake\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data manipulation and analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Multi-dimensional arrays and datasets (e.g., NetCDF, Zarr)\n",
        "import xarray as xr\n",
        "\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# Planetary Computer tools for STAC API access and authentication\n",
        "import pystac_client\n",
        "import planetary_computer as pc\n",
        "\n",
        "from datetime import date\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74652f9-d132-4bd2-b444-beabc82fbeb0",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell20"
      },
      "source": [
        "## Extracting TerraClimate Data Using API Calls\n",
        "\n",
        "The API-based method allows us to efficiently access **TerraClimate** data for specific regions and time periods through the [Microsoft Planetary Computer](https://planetarycomputer.microsoft.com/), ensuring scalability and reproducibility of the process.\n",
        "\n",
        "Through the API, we can extract climate variables such as **Potential Evapotranspiration (PET)**, which represents the atmospheric demand for water. This variable provides important insights into surface moisture balance and helps improve the accuracy of water quality modeling.\n",
        "\n",
        "This approach ensures consistent, automated retrieval of high-resolution climate data that can be easily integrated with satellite-derived features for comprehensive environmental and hydrological analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33d42366-3ab5-47b4-bf86-32bb9c63eb7a",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell4"
      },
      "source": [
        "### Loading and Mapping TerraClimate Data\n",
        "\n",
        "This section demonstrates how **TerraClimate climate variables**, such as **Potential Evapotranspiration (PET)**, are loaded and mapped to sampling locations.\n",
        "\n",
        "- The **load_terraclimate_dataset** function opens the TerraClimate Zarr/NetCDF dataset from the Microsoft Planetary Computer, handling storage options automatically.\n",
        "- The **filterg** function filters the dataset for the desired time range (2011–2015) and the spatial extent corresponding to the study region. The resulting data is converted into a pandas DataFrame with standardized column names.\n",
        "- The **assign_nearest_climate** function maps each sampling location to its **nearest TerraClimate grid point** using a KD-tree and assigns the climate variable values corresponding to the closest timestamp.\n",
        "\n",
        "This workflow ensures efficient, reproducible retrieval of climate variables, while allowing participants to work with pre-extracted CSV files for faster benchmarking and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad324597-e798-4127-8668-da9ab6873467",
      "metadata": {
        "language": "python",
        "name": "cell5"
      },
      "outputs": [],
      "source": [
        "def load_terraclimate_dataset():\n",
        "    catalog = pystac_client.Client.open(\n",
        "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
        "        modifier=pc.sign_inplace,\n",
        "    )\n",
        "    collection = catalog.get_collection(\"terraclimate\")\n",
        "    asset = collection.assets[\"zarr-abfs\"]\n",
        "\n",
        "    if \"xarray:storage_options\" in asset.extra_fields:\n",
        "        ds = xr.open_zarr(\n",
        "            asset.href,\n",
        "            storage_options=asset.extra_fields[\"xarray:storage_options\"],\n",
        "            consolidated=True,\n",
        "        )\n",
        "    else:\n",
        "        ds = xr.open_dataset(\n",
        "            asset.href,\n",
        "            **asset.extra_fields[\"xarray:open_kwargs\"],\n",
        "        )\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cd1bc1-0c50-4fee-926c-459927f397e2",
      "metadata": {
        "language": "python",
        "name": "cell6"
      },
      "outputs": [],
      "source": [
        "# --- Filtering function (kept identical) ---\n",
        "def filterg(ds, var):\n",
        "    ds_2011_2015 = ds[var].sel(time=slice(\"2011-01-01\", \"2015-12-31\"))\n",
        "\n",
        "    df_var_append = []\n",
        "    for i in tqdm(range(len(ds_2011_2015.time))):\n",
        "        df_var = ds_2011_2015.isel(time=i).to_dataframe().reset_index()\n",
        "        df_var_filter = df_var[\n",
        "            (df_var['lat'] > -35.18) & (df_var['lat'] < -21.72) &\n",
        "            (df_var['lon'] > 14.97) & (df_var['lon'] < 32.79)\n",
        "        ]\n",
        "        df_var_append.append(df_var_filter)\n",
        "\n",
        "    df_var_final = pd.concat(df_var_append, ignore_index=True)\n",
        "    print(f\"Filtering for {var} completed\")\n",
        "\n",
        "    df_var_final['time'] = df_var_final['time'].astype(str)\n",
        "\n",
        "    # Column mapping\n",
        "    col_mapping = {\"lat\": \"Latitude\", \"lon\": \"Longitude\", \"time\": \"Sample Date\"}\n",
        "    df_var_final = df_var_final.rename(columns=col_mapping)\n",
        "\n",
        "    return df_var_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1a70cf-cfdb-4256-808d-087d591e806f",
      "metadata": {
        "language": "python",
        "name": "cell7"
      },
      "outputs": [],
      "source": [
        "# --- Climate variable assignment function (unchanged logic) ---\n",
        "def assign_nearest_climate(sa_df, climate_df, var_name):\n",
        "    \"\"\"\n",
        "    Map nearest climate variable values to a new DataFrame \n",
        "    containing only the specified variable column.\n",
        "    \"\"\"\n",
        "    sa_coords = np.radians(sa_df[['Latitude', 'Longitude']].values)\n",
        "    climate_coords = np.radians(climate_df[['Latitude', 'Longitude']].values)\n",
        "\n",
        "    tree = cKDTree(climate_coords)\n",
        "    dist, idx = tree.query(sa_coords, k=1)\n",
        "\n",
        "    nearest_points = climate_df.iloc[idx].reset_index(drop=True)\n",
        "\n",
        "    sa_df = sa_df.reset_index(drop=True)\n",
        "    sa_df[['nearest_lat', 'nearest_lon']] = nearest_points[['Latitude', 'Longitude']]\n",
        "\n",
        "    sa_df['Sample Date'] = pd.to_datetime(sa_df['Sample Date'], dayfirst=True, errors='coerce')\n",
        "    climate_df['Sample Date'] = pd.to_datetime(climate_df['Sample Date'], dayfirst=True, errors='coerce')\n",
        "\n",
        "    climate_values = []\n",
        "\n",
        "    for i in tqdm(range(len(sa_df)), desc=f\"Mapping {var_name.upper()} values\"):\n",
        "        sample_date = sa_df.loc[i, 'Sample Date']\n",
        "        nearest_lat = sa_df.loc[i, 'nearest_lat']\n",
        "        nearest_lon = sa_df.loc[i, 'nearest_lon']\n",
        "\n",
        "        subset = climate_df[\n",
        "            (climate_df['Latitude'] == nearest_lat) &\n",
        "            (climate_df['Longitude'] == nearest_lon)\n",
        "        ]\n",
        "\n",
        "        if subset.empty:\n",
        "            climate_values.append(np.nan)\n",
        "            continue\n",
        "\n",
        "        nearest_idx = (subset['Sample Date'] - sample_date).abs().idxmin()\n",
        "        climate_values.append(subset.loc[nearest_idx, var_name])\n",
        "\n",
        "    output_df = pd.DataFrame({var_name: climate_values})\n",
        "\n",
        "    \n",
        "    return output_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8065c081-51ca-439e-b42d-fa1afcb961e9",
      "metadata": {
        "codeCollapsed": true,
        "name": "cell8"
      },
      "source": [
        "### Extracting features for the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54291642-9b6a-42a5-8370-12c230b755d5",
      "metadata": {
        "language": "python",
        "name": "cell9"
      },
      "outputs": [],
      "source": [
        "Water_Quality_df = pd.read_csv(\"water_quality_training_dataset.csv\")\n",
        "display(Water_Quality_df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd9dbc3-56c7-46be-b921-666d55a50185",
      "metadata": {
        "language": "python",
        "name": "cell10"
      },
      "outputs": [],
      "source": [
        "Water_Quality_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34229a57-1579-4615-8b07-64fde8299e3e",
      "metadata": {
        "language": "python",
        "name": "cell11"
      },
      "outputs": [],
      "source": [
        "# Load TerraClimate dataset and extract multiple climate variables\n",
        "ds = load_terraclimate_dataset()\n",
        "\n",
        "# Extract multiple climate variables\n",
        "print(\"Extracting PET...\")\n",
        "tc_pet = filterg(ds, 'pet')\n",
        "pet_df = assign_nearest_climate(Water_Quality_df, tc_pet, 'pet')\n",
        "\n",
        "print(\"Extracting Precipitation...\")\n",
        "tc_ppt = filterg(ds, 'ppt')\n",
        "ppt_df = assign_nearest_climate(Water_Quality_df, tc_ppt, 'ppt')\n",
        "\n",
        "print(\"Extracting Temperature...\")\n",
        "tc_tmax = filterg(ds, 'tmax')\n",
        "tmax_df = assign_nearest_climate(Water_Quality_df, tc_tmax, 'tmax')\n",
        "\n",
        "tc_tmin = filterg(ds, 'tmin')\n",
        "tmin_df = assign_nearest_climate(Water_Quality_df, tc_tmin, 'tmin')\n",
        "\n",
        "print(\"Extracting Soil Moisture...\")\n",
        "tc_soil = filterg(ds, 'soil')\n",
        "soil_df = assign_nearest_climate(Water_Quality_df, tc_soil, 'soil')\n",
        "\n",
        "# Combine all climate features\n",
        "Terraclimate_training_df = pd.concat([\n",
        "    pet_df, ppt_df, tmax_df, tmin_df, soil_df\n",
        "], axis=1)\n",
        "\n",
        "print(f\"Climate feature extraction complete. Features: {list(Terraclimate_training_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2eebd3-78ab-4306-ba51-57542dee97bc",
      "metadata": {
        "language": "python",
        "name": "cell12"
      },
      "outputs": [],
      "source": [
        "# Add location and date information\n",
        "Terraclimate_training_df['Latitude'] = Water_Quality_df['Latitude']\n",
        "Terraclimate_training_df['Longitude'] = Water_Quality_df['Longitude']\n",
        "Terraclimate_training_df['Sample Date'] = Water_Quality_df['Sample Date']\n",
        "\n",
        "# Create derived climate features\n",
        "eps = 1e-10\n",
        "Terraclimate_training_df['temp_range'] = Terraclimate_training_df['tmax'] - Terraclimate_training_df['tmin']\n",
        "Terraclimate_training_df['temp_mean'] = (Terraclimate_training_df['tmax'] + Terraclimate_training_df['tmin']) / 2\n",
        "Terraclimate_training_df['aridity_index'] = Terraclimate_training_df['pet'] / (Terraclimate_training_df['ppt'] + eps)\n",
        "Terraclimate_training_df['water_balance'] = Terraclimate_training_df['ppt'] - Terraclimate_training_df['pet']\n",
        "\n",
        "# Add seasonality encoding\n",
        "Terraclimate_training_df['Sample Date'] = pd.to_datetime(Terraclimate_training_df['Sample Date'], dayfirst=True)\n",
        "Terraclimate_training_df['month'] = Terraclimate_training_df['Sample Date'].dt.month\n",
        "Terraclimate_training_df['day_of_year'] = Terraclimate_training_df['Sample Date'].dt.dayofyear\n",
        "Terraclimate_training_df['season_sin'] = np.sin(2 * np.pi * Terraclimate_training_df['day_of_year'] / 365.25)\n",
        "Terraclimate_training_df['season_cos'] = np.cos(2 * np.pi * Terraclimate_training_df['day_of_year'] / 365.25)\n",
        "\n",
        "# Reorder columns\n",
        "climate_columns = ['Latitude', 'Longitude', 'Sample Date', \n",
        "                  'pet', 'ppt', 'tmax', 'tmin', 'soil',\n",
        "                  'temp_range', 'temp_mean', 'aridity_index', 'water_balance',\n",
        "                  'month', 'day_of_year', 'season_sin', 'season_cos']\n",
        "\n",
        "Terraclimate_training_df = Terraclimate_training_df[climate_columns]\n",
        "Terraclimate_training_df.to_csv('terraclimate_features_training.csv', index=False)\n",
        "\n",
        "print(f\"Enhanced climate features saved. Total features: {len(climate_columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c2114e6-8204-4cf7-8f0d-16745cb1fd75",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell13"
      },
      "outputs": [],
      "source": [
        "# Preview File\n",
        "display(Terraclimate_training_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2552f2-b2ec-40d2-816f-43293c78c9f6",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "Terraclimate_training_df.to_csv(\"/tmp/terraclimate_features_training.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef0bfba-25a3-4089-9023-db244201ace7",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "session.sql(f\"\"\"\n",
        "    PUT file:///tmp/terraclimate_features_training.csv\n",
        "    snow://workspace/USER$.PUBLIC.DEFAULT$/versions/live/\n",
        "    AUTO_COMPRESS=FALSE\n",
        "    OVERWRITE=TRUE\n",
        "\"\"\").collect()\n",
        "\n",
        "print(\"File saved! Refresh the browser to see the files in the sidebar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b91cf806-2228-4b46-a0c1-8b1afb01bc6d",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "cell14"
      },
      "source": [
        "### Extracting features for the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed3f63d-3a89-4145-b2a6-917c2e98fa4e",
      "metadata": {
        "language": "python",
        "name": "cell15"
      },
      "outputs": [],
      "source": [
        "Validation_df=pd.read_csv('submission_template.csv')\n",
        "display(Validation_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b32f7a00-313d-4acf-8a02-2d755703da27",
      "metadata": {
        "language": "python",
        "name": "cell16"
      },
      "outputs": [],
      "source": [
        "Validation_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4a6c090-39df-4923-b03b-1fc257e2952b",
      "metadata": {
        "language": "python",
        "name": "cell17"
      },
      "outputs": [],
      "source": [
        "# Extract climate features for validation dataset using the same climate data\n",
        "print(\"Extracting validation climate features...\")\n",
        "\n",
        "pet_val_df = assign_nearest_climate(Validation_df, tc_pet, 'pet')\n",
        "ppt_val_df = assign_nearest_climate(Validation_df, tc_ppt, 'ppt')\n",
        "tmax_val_df = assign_nearest_climate(Validation_df, tc_tmax, 'tmax')\n",
        "tmin_val_df = assign_nearest_climate(Validation_df, tc_tmin, 'tmin')\n",
        "soil_val_df = assign_nearest_climate(Validation_df, tc_soil, 'soil')\n",
        "\n",
        "# Combine all climate features\n",
        "Terraclimate_validation_df = pd.concat([\n",
        "    pet_val_df, ppt_val_df, tmax_val_df, tmin_val_df, soil_val_df\n",
        "], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0fc36a-b4b7-44c4-bc59-7a1f6216d5ae",
      "metadata": {
        "language": "python",
        "name": "cell18"
      },
      "outputs": [],
      "source": [
        "# Add location and date information for validation\n",
        "Terraclimate_validation_df['Latitude'] = Validation_df['Latitude']\n",
        "Terraclimate_validation_df['Longitude'] = Validation_df['Longitude']\n",
        "Terraclimate_validation_df['Sample Date'] = Validation_df['Sample Date']\n",
        "\n",
        "# Create the same derived climate features for validation\n",
        "eps = 1e-10\n",
        "Terraclimate_validation_df['temp_range'] = Terraclimate_validation_df['tmax'] - Terraclimate_validation_df['tmin']\n",
        "Terraclimate_validation_df['temp_mean'] = (Terraclimate_validation_df['tmax'] + Terraclimate_validation_df['tmin']) / 2\n",
        "Terraclimate_validation_df['aridity_index'] = Terraclimate_validation_df['pet'] / (Terraclimate_validation_df['ppt'] + eps)\n",
        "Terraclimate_validation_df['water_balance'] = Terraclimate_validation_df['ppt'] - Terraclimate_validation_df['pet']\n",
        "\n",
        "# Add seasonality encoding for validation\n",
        "Terraclimate_validation_df['Sample Date'] = pd.to_datetime(Terraclimate_validation_df['Sample Date'], dayfirst=True)\n",
        "Terraclimate_validation_df['month'] = Terraclimate_validation_df['Sample Date'].dt.month\n",
        "Terraclimate_validation_df['day_of_year'] = Terraclimate_validation_df['Sample Date'].dt.dayofyear\n",
        "Terraclimate_validation_df['season_sin'] = np.sin(2 * np.pi * Terraclimate_validation_df['day_of_year'] / 365.25)\n",
        "Terraclimate_validation_df['season_cos'] = np.cos(2 * np.pi * Terraclimate_validation_df['day_of_year'] / 365.25)\n",
        "\n",
        "# Use the same column order as training\n",
        "climate_columns = ['Latitude', 'Longitude', 'Sample Date', \n",
        "                  'pet', 'ppt', 'tmax', 'tmin', 'soil',\n",
        "                  'temp_range', 'temp_mean', 'aridity_index', 'water_balance',\n",
        "                  'month', 'day_of_year', 'season_sin', 'season_cos']\n",
        "\n",
        "Terraclimate_validation_df = Terraclimate_validation_df[climate_columns]\n",
        "Terraclimate_validation_df.to_csv('terraclimate_features_validation.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23777c24-0347-4b35-ae06-f53ead075493",
      "metadata": {
        "language": "python",
        "name": "cell19"
      },
      "outputs": [],
      "source": [
        "# Preview File\n",
        "display(Terraclimate_validation_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8d9c1a-84d2-4f4b-9289-7850f2d80e5d",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "Terraclimate_validation_df.to_csv(\"/tmp/terraclimate_features_validation.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e8f853-d3ac-40e3-a5c6-1617c52f438e",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "session.sql(f\"\"\"\n",
        "    PUT file:///tmp/terraclimate_features_validation.csv\n",
        "    snow://workspace/USER$.PUBLIC.DEFAULT$/versions/live/\n",
        "    AUTO_COMPRESS=FALSE\n",
        "    OVERWRITE=TRUE\n",
        "\"\"\").collect()\n",
        "\n",
        "\n",
        "print(\"File saved! Refresh the browser to see the files in the sidebar\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e5b2806-b54b-4182-bf85-680f13edf181",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.3"
    },
    "lastEditStatus": {
      "authorEmail": "kushijannu14@gmail.com",
      "authorId": "8166278287717",
      "authorName": "KUSHIJANNU12345",
      "lastEditTime": 1765775413840,
      "notebookId": "y3vizltueoic3nbogu5h",
      "sessionId": "e748d7dd-17f5-41c2-8af3-9fbc693bd759"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
